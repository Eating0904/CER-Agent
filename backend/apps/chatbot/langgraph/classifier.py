"""
æ„åœ–åˆ†é¡å™¨ (Context-Aware Router)
ä½¿ç”¨ ChatGoogleGenerativeAI åˆ†æå®Œæ•´å°è©±æ­·å²ï¼Œåˆ¤æ–·ä½¿ç”¨è€…æ„åœ–
"""

import json
from typing import Any, List
from .prompts import CLASSIFIER_PROMPT
from langchain_core.messages import BaseMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI


class IntentClassifier:
    """æ„åœ–åˆ†é¡å™¨ - Context-Aware Router"""

    def __init__(self):
        """
        åˆå§‹åŒ–åˆ†é¡å™¨
        """
        # ä½¿ç”¨ LangChain çš„ ChatGoogleGenerativeAI
        # API key æœƒè‡ªå‹•å¾ç’°å¢ƒè®Šæ•¸ GOOGLE_API_KEY è®€å–
        self.llm = ChatGoogleGenerativeAI(
            model='gemini-2.5-pro',
            temperature=0.1,  # é™ä½éš¨æ©Ÿæ€§ï¼Œä½¿åˆ†é¡æ›´ç©©å®š
        )

        # ä½¿ç”¨é å®šç¾©çš„ prompt
        self.system_prompt = CLASSIFIER_PROMPT

    def _extract_json(self, text: str) -> str:
        """å¾æ–‡æœ¬ä¸­æå– JSON"""
        # æ‰¾ç¬¬ä¸€å€‹ { çš„ä½ç½®
        start = text.find('{')
        if start == -1:
            return text.strip()

        # æ‰¾æœ€å¾Œä¸€å€‹ } çš„ä½ç½®
        end = text.rfind('}')
        if end == -1:
            return text.strip()

        # æå– { åˆ° } ä¹‹é–“çš„å…§å®¹ï¼ˆåŒ…å« { å’Œ }ï¼‰
        json_str = text[start : end + 1]

        return json_str

    def classify(self, messages: List[BaseMessage], callbacks: List[Any] = None) -> dict:
        """
        åˆ†é¡ä½¿ç”¨è€…æ„åœ–

        Args:
            messages: å®Œæ•´å°è©±æ­·å²
                     æ¯å‰‡ HumanMessage çš„ content æ˜¯ JSON å­—ä¸²ï¼š{"query": "ä½¿ç”¨è€…å•é¡Œ", "context": {...å¿ƒæ™ºåœ–è³‡æ–™...}}
            callbacks: LangChain callbacks for tracing

        Returns:
            dict: åŒ…å« reasoning å’Œ next_action çš„å­—å…¸
                  next_action ç‚º "operator_support" æˆ– "cer_cognitive_support"
        """
        # ä½¿ç”¨ List Injectionï¼ŒLLM æœƒè‡ªå‹•è®€å– JSON ä¸­çš„ query
        final_messages = [SystemMessage(content=self.system_prompt)] + messages

        try:
            # å‘¼å« LLMï¼ˆç›´æ¥å‚³é List[BaseMessage]ï¼‰
            response = self.llm.invoke(
                final_messages, config={'callbacks': callbacks, 'run_name': 'IntentClassifier'}
            )
            print(f'\nğŸ’¡ åˆ†é¡å™¨å›æ‡‰: {response.content}')

            # æå–ä¸¦è§£æ JSON
            json_text = self._extract_json(response.content)
            result = json.loads(json_text)

            # é©—è­‰å›æ‡‰æ ¼å¼
            if 'next_action' not in result:
                raise ValueError('åˆ†é¡çµæœç¼ºå°‘ next_action æ¬„ä½')


            # é©—è­‰åˆ†é¡çµæœæ˜¯å¦åˆæ³•
            valid_actions = ['operator_support', 'cer_cognitive_support']
            if result['next_action'] not in valid_actions:
                raise ValueError(f'ç„¡æ•ˆçš„åˆ†é¡çµæœ: {result["next_action"]}')

            return result

        except json.JSONDecodeError as e:
            print(f'\nâš ï¸  JSON è§£æéŒ¯èª¤: {e}')
            print(f'åŸå§‹å›æ‡‰: {response.content}')
            print(f'æå–çš„ JSON: {json_text[:200] if "json_text" in locals() else "N/A"}')
            # é è¨­å›å‚³ operator_support
            return {
                'reasoning': 'JSON è§£æå¤±æ•—ï¼Œé è¨­ç‚ºä»‹é¢æ”¯æ´',
                'next_action': 'operator_support',
            }
        except Exception as e:
            print(f'\nâŒ åˆ†é¡å™¨éŒ¯èª¤: {e}')
            if 'response' in locals():
                print(f'åŸå§‹å›æ‡‰: {response.content}')
            # é è¨­å›å‚³ operator_support
            return {
                'reasoning': f'ç™¼ç”ŸéŒ¯èª¤: {str(e)}',
                'next_action': 'operator_support',
            }
